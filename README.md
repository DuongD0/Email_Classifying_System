# Email Classification

## Overview
This project classifies emails into three buckets — `Normal` (legitimate), `Spam`, and `Fraud` — using a TF-IDF + scikit-learn pipeline. The workflow mirrors the richer preprocessing used in the support-email classifier bot: HTML stripping, token filtering, stopword removal, and lemmatisation (see `text_preprocessing.py`). You can train either a logistic-regression baseline or a chi-squared-filtered random forest and persist the pipeline to both `.joblib` and `.pkl` artefacts for easy reuse.

## Technology Stack
- Python 3.9+
- scikit-learn (model zoo, metrics, vectorizers)
- pandas & numpy (data manipulation)
- nltk (English stopwords)
- matplotlib & seaborn (visualization)
- joblib (model persistence)
- argparse (CLI controls)

## Dataset & Experiment Setup
- Data source: balanced corpus of 3,000 emails (1,000 per class) generated by `Extract_email.py`.
- Train/test split: 70/30 using `train_test_split` with `random_state=111`.
- Feature suites explored:
  - TF-IDF (baseline, no stemming)
  - TF-IDF with stemming
  - TF-IDF + email length feature
  - Count Vectorizer (with and without stemming)
- Model families: SVC, KNN, MultinomialNB, Decision Tree, Logistic Regression, Random Forest, AdaBoost, Bagging, ExtraTrees, SGD (hinge/logistic), and multiple voting ensembles.

## Latest Training Snapshot
_Output from `python Email_Classification.py` on the bundled dataset_

| Feature Block | Best Model | Accuracy | Macro Precision | Macro Recall | Notes |
| --- | --- | --- | --- | --- | --- |
| TF-IDF (no stem) | SVC (sigmoid, γ≈0.95) | **0.9733** | 0.977 | 0.976 | Persisted to `models/svc_classifier.joblib` |
| TF-IDF (no stem) | SGD Logistic | 0.9756 | 0.978 | 0.978 | Close runner-up |
| TF-IDF (stemmed) | MultinomialNB | 0.9733 | 0.973 | 0.973 | |
| TF-IDF (stemmed) | Vote(SVC, BgC, RF) | 0.9744 | 0.975 | 0.974 | |
| Count Vectorizer | MultinomialNB | 0.9733 | 0.973 | 0.973 | |
| Count Vectorizer (stemmed) | MultinomialNB | 0.9756 | 0.976 | 0.976 | |

Confusion-matrix highlights for the persisted SVC (TF-IDF, no stem):
- FRAUD: precision 0.96, recall 0.99
- SPAM: precision 0.97, recall 0.96
- NORMAL: precision 1.00, recall 0.98

The pipeline automatically overwrites `models/tfidf_vectorizer.joblib` and `models/svc_classifier.joblib` with the best TF-IDF model from the baseline block; delete either file to force a full retrain.

## CLI & Workflow
```bash
# Train with class balancing (default logistic regression)
python Email_Classification.py

# Switch classifiers or feature-selection knobs
python Email_Classification.py --model rf --k-best 1000 --max-features 100000 --test-size 0.25

# Train without balancing
python Email_Classification.py --no-balance

# Persist joblib/pickle to custom locations
python Email_Classification.py --model rf --pickle-path models/custom.pkl --model-path models/custom.joblib
```

Sample results on the balanced dataset (`--max-features 100000`, `--test-size 0.25`):

| Model | Label   | Precision | Recall | F1 | Support |
|-------|---------|-----------|--------|----|---------|
| Logistic | Normal  | 0.99 | 0.98 | 0.98 | 8,596 |
| Logistic | Spam    | 0.94 | 0.96 | 0.95 | 8,596 |
| Logistic | Fraud   | 0.97 | 0.95 | 0.96 | 8,597 |
| Logistic | **Accuracy** | | | **0.96** | 25,789 |
| Random Forest (`--model rf --k-best 1000`) | Normal | 0.97 | 0.96 | 0.97 | 8,596 |
| Random Forest | Spam   | 0.93 | 0.93 | 0.93 | 8,596 |
| Random Forest | Fraud  | 0.94 | 0.94 | 0.94 | 8,597 |
| Random Forest | **Accuracy** | | | **0.95** | 25,789 |

Each training run saves the pipeline to `models/email_classifier.joblib` and `models/email_classifier.pkl` (paths configurable via CLI).
Pick whichever artefact aligns with your deployment stack—`joblib` for fast Python reloads or the plain pickle for broader tooling—and wire it into your Gmail management app without retraining every start-up.

**Pipeline Run**
- `python Extract_email.py` (optionally `--balance`) to refresh the combined dataset.
- `python Email_Classification.py` with any tuning flags to train and persist a model.
- `python Email_Classification.py --predict "<email>"` to inspect predictions, class percentages, and the driving tokens.
- Load `models/email_classifier.joblib` or `models/email_classifier.pkl` to reuse the trained pipeline instantly.

## Quick Predictions
Use the `--predict` flag or instantiate `EmailClassifier` to score ad-hoc messages with the saved model.

```bash
python Email_Classification.py --predict "Dear customer, verify your account immediately..."
# Predicted label: 2 (Fraud)
# ..prints class probabilities and top suspicious words for Spam/Fraud
```

Or in Python:

```python
from Email_Classification import EmailClassifier

clf = EmailClassifier()
label, label_name = clf.predict("Meeting agenda attached")
print(label, label_name)  # -> 0 Normal (after training)
```

## Tips
- Run `python Extract_email.py --balance` before training if you want the classifier to see a balanced class distribution.
- Delete `models/email_classifier.joblib` to force a clean retrain.
- Use `--model rf --k-best <k>` to reproduce the random-forest + chi-squared flow from the support-email project.
- Use `--max-features` to trade accuracy vs. vocabulary size/performance.