# Email Classification

## Overview
This project classifies emails into `NORMAL`, `SPAM`, or `FRAUD` using a classical machine‑learning pipeline built on top of scikit-learn. The workflow covers text cleaning, extensive model benchmarking, evaluation, and artifact persistence so the best performer can be reused for real-time detection.

## Technology Stack
- Python 3.9+
- scikit-learn (model zoo, metrics, vectorizers)
- pandas & numpy (data manipulation)
- nltk (English stopwords)
- matplotlib & seaborn (visualization)
- joblib (model persistence)
- argparse (CLI controls)

## Dataset & Experiment Setup
- Data source: balanced corpus of 3,000 emails (1,000 per class) generated by `Extract_email.py`.
- Train/test split: 70/30 using `train_test_split` with `random_state=111`.
- Feature suites explored:
  - TF-IDF (baseline, no stemming)
  - TF-IDF with stemming
  - TF-IDF + email length feature
  - Count Vectorizer (with and without stemming)
- Model families: SVC, KNN, MultinomialNB, Decision Tree, Logistic Regression, Random Forest, AdaBoost, Bagging, ExtraTrees, SGD (hinge/logistic), and multiple voting ensembles.

## Latest Training Snapshot
_Output from `python Email_Classification.py` on the bundled dataset_

| Feature Block | Best Model | Accuracy | Macro Precision | Macro Recall | Notes |
| --- | --- | --- | --- | --- | --- |
| TF-IDF (no stem) | SVC (sigmoid, γ≈0.95) | **0.9733** | 0.977 | 0.976 | Persisted to `models/svc_classifier.joblib` |
| TF-IDF (no stem) | SGD Logistic | 0.9756 | 0.978 | 0.978 | Close runner-up |
| TF-IDF (stemmed) | MultinomialNB | 0.9733 | 0.973 | 0.973 | |
| TF-IDF (stemmed) | Vote(SVC, BgC, RF) | 0.9744 | 0.975 | 0.974 | |
| Count Vectorizer | MultinomialNB | 0.9733 | 0.973 | 0.973 | |
| Count Vectorizer (stemmed) | MultinomialNB | 0.9756 | 0.976 | 0.976 | |

Confusion-matrix highlights for the persisted SVC (TF-IDF, no stem):
- FRAUD: precision 0.96, recall 0.99
- SPAM: precision 0.97, recall 0.96
- NORMAL: precision 1.00, recall 0.98

The pipeline automatically overwrites `models/tfidf_vectorizer.joblib` and `models/svc_classifier.joblib` with the best TF-IDF model from the baseline block; delete either file to force a full retrain.

## CLI & Workflow
```bash
# End-to-end training (overwrites cached artifacts)
python Email_Classification.py

# Skip training and just load the saved artifacts
python Email_Classification.py --skip-training

# Retrain even if artifacts exist (silences overwrite warning)
python Email_Classification.py --force-retrain
```

### Data Preparation
```bash
python Extract_email.py  # regenerates Datasets/final_dataset.csv
```
Adjust dataset paths inside `Extract_email.py` if your raw corpora live elsewhere.

## Real-Time Detection
```python
from Email_Classification import RealTimeEmailDetector

detector = RealTimeEmailDetector()
label = detector.predict("Congratulations, you've won...")
print(label)  # -> SPAM / FRAUD / NORMAL
```
The helper loads the persisted vectorizer and classifier, applies the same preprocessing (punctuation removal + stopword filtering), and returns a label in real time. Embed this call in a Gmail webhook, IMAP poller, or any service that hands you raw email bodies.

## Troubleshooting & Tips
- **Missing stopwords**: `python -c "import nltk; nltk.download('stopwords')"`
- **Artifacts not updating**: rerun with `--force-retrain` or delete the files in `models/`.
- **Long training runs**: comment out experiment blocks you do not need, or subsample for experimentation.
- **Dataset not found**: ensure `Datasets/final_dataset.csv` exists or update `input_dataset` in `Email_Classification.py`.

For deeper experimentation, tweak hyperparameters inside `Email_Classification.py`, extend preprocessing via `Data_Preprocessing`, or add custom voting configurations. The README will stay current with the latest benchmark results so you can track progress over time.
